# -*- coding: utf-8 -*-
"""[DS200] UAD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QZJsSZu9dIV-ZcfNTCfPA_ZB0AE-PFqk

- Sử dụng các phương pháp UAD như i-Forest, SR, STL, RC-Forest và Luminol để phát hiện bất thường trong dữ liệu giao dịch.
- Mỗi phương pháp sẽ tạo ra một tập nhãn ban đầu cho các điểm dữ liệu trong chuỗi thời gian. - *Labeling function (LFs)*

5 mô hình UAD: https://realseries.readthedocs.io/en/latest/pages/installation.html

(hiện tại mới fix được 4 model:  i-Forest, SR, RC-Forest và Luminol) - thêm 1 model LOF

# **1. Import**
"""

!pip install luminol

!pip install rrcf

!git clone https://github.com/xchuwenbo/realseries.git

#!apt-get install python2.7
#!ln -s /usr/bin/python2.7 /usr/bin/python
#!pip install statsmodels==0.10.2

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

import warnings
warnings.filterwarnings("ignore")

from sklearn.decomposition import PCA
import realseries
from realseries.realseries.models.iforest import IForest
from realseries.realseries.models.sr import SpectralResidual
#from realseries.realseries.models.stl import STL
from realseries.realseries.models.lumino import Lumino
from realseries.realseries.models.rcforest import RCForest
from sklearn.svm import OneClassSVM

from google.colab import drive
drive.mount('/content/drive')

path = '/content/drive/MyDrive/Học kì 6/DS200/Dataset/'
path_split = '/content/drive/MyDrive/Học kì 6/DS200/Dataset/Split/'

"""# **2. Function**"""

def pro(data):
  data['Date'] = pd.to_datetime(data['Date'])
  data = data.sort_values('Date')
  data = data.set_index('Date')
  return data

def load_anomaly(path):
    train_data = pro(pd.read_csv(path + "train_data.csv"))
    train_labels = pd.read_csv(path + "train_labels.csv")
    test_data = pro(pd.read_csv(path + "test_data.csv"))
    test_labels = pd.read_csv(path + "test_labels.csv")
    return train_data, train_labels, test_data, test_labels


data = pd.read_csv(path+'Data_processed.csv')

from sklearn.neighbors import LocalOutlierFactor

def init_model():
    # Khởi tạo mô hình
    # IForest
    IF = IForest(n_estimators=1000, max_samples='auto', contamination=0.01, random_state=42)

    # SR (Spectral Residual)
    SR = SpectralResidual(
        series=None,  # Sẽ được cung cấp sau
        threshold=0.5,
        mag_window=200,
        score_window=10
    )

    # RC-Forest (Random Cut Forest)
    rcforest_model = RCForest(
        shingle_size=1,
        num_trees=100,
        tree_size=50
    )

    # Luminol
    lumino_model = Lumino()

    """# OneClassSVM
    OCsvm_model = OCSVM()"""

    clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)

    return IF, SR, rcforest_model, lumino_model, clf

def train_model(IF, SR, rcforest_model, lumino_model, clf, input):
    # Huấn luyện mô hình
    # i-Forest
    IF.fit(input)
    if_score = IF.detect(input)
    thres = np.percentile(if_score, 99)
    # Xác định nhãn bất thường (0: bình thường, 1: bất thường)
    pred_label_if = (if_score > thres).astype(int)

    # SR (Spectral Residual)
    SR.series = np.array(input).flatten()
    pred_label_sr = SR.detect()
    sr_label = np.array(pred_label_sr["isAnomaly"])
    sr_score = np.array(pred_label_sr["score"])

    """# STL (Seasonal and Trend decomposition using Loess)
    decomp = STL_model.fit(
        input,
        period=90,
        lo_frac=0.6,
        lo_delta=0.01
    )
    resid = np.array(decomp["resid"].squeeze())
    stl_score = abs(resid)
    stl_score = (stl_score - np.min(stl_score)) / (np.max(stl_score) - np.min(stl_score))
    thres = stl_score.min() + 0.7 * (stl_score.max() - stl_score.min())
    stl_label = (stl_score > thres).astype(int)"""

    # RC-Forest (Random Cut Forest)
    rcforest_score = rcforest_model.detect(input)
    min_score = np.nanmin(rcforest_score)
    rcforest_score = np.nan_to_num(rcforest_score, nan=min_score)
    thres = np.percentile(rcforest_score, 99)
    pred_label_rcforest = (rcforest_score > thres).astype(int)

    # Luminol
    lumino_score = lumino_model.detect(np.array(input).flatten())
    thres = lumino_score.min() + 0.7 * (lumino_score.max() - lumino_score.min())
    pred_label_lumino = (lumino_score > thres).astype(int)

    """# OneClassSVM
    OCsvm_model.fit(input)
    svm_score = OCsvm_model.detect(input)
    thres = np.percentile(svm_score, 99)
    svm_label = (svm_score > thres).astype(int)"""

    # clf
    clf.fit(input)
    lof_scores = -clf.negative_outlier_factor_
    lof_scores = (lof_scores - np.min(lof_scores)) / (np.max(lof_scores) - np.min(lof_scores))
    pred_label_clf = (lof_scores > thres).astype(int)

    return pred_label_if, if_score, sr_label, sr_score, pred_label_rcforest, rcforest_score, pred_label_lumino, lumino_score, lof_scores, pred_label_clf

def add_results(df, pred_label_if, if_score, sr_label, sr_score, pred_label_rcforest, rcforest_score, pred_label_lumino, lumino_score, lof_scores, pred_label_clf):
    # Thêm cột nhãn bất thường và điểm số bất thường vào dữ liệu gốc
    df['IForest Label'] = pred_label_if
    df['IForest Score'] = if_score

    df['SR Label'] = sr_label
    df['SR Score'] = sr_score

    df['RC-Forest Label'] = pred_label_rcforest
    df['RC-Forest Score'] = rcforest_score

    df['Luminol Label'] = pred_label_lumino
    df['Luminol Score'] = lumino_score

    """df['STL Label'] = stl_label
    df['STL Score'] = stl_score

    df['OneClassSVM Label'] = svm_label
    df['OneClassSVM Score'] = svm_score"""

    df['LOF Label'] = pred_label_clf
    df['LOF Score'] = lof_scores

    return df

def uad(input, df):
    IF, SR, rcforest_model, lumino_model, clf  = init_model()
    #input = df.values.reshape(-1,1)
    pred_label_if, if_score, sr_label, sr_score, pred_label_rcforest, rcforest_score, pred_label_lumino, lumino_score, pred_label_clf, lof_scores = train_model(
        IF, SR, rcforest_model, lumino_model, clf, input)
    df_result = add_results(df, pred_label_if, if_score, sr_label, sr_score, pred_label_rcforest, rcforest_score,
                            pred_label_lumino, lumino_score, pred_label_clf, lof_scores)
    return df_result

"""# **3. Thực thi**"""

train_data, train_label, test_data, test_label = load_anomaly(path_split)

train_data.info()
train_data.head(2)

"""## **3.1. Train set**"""

data = train_data.copy()

pca = PCA(n_components=1)
# Chuẩn hóa dữ liệu
normalized_data = (data - data.mean()) / data.std()
# Thực hiện PCA
transformed_data = pca.fit_transform(normalized_data)

data_uad = uad(transformed_data, data)

col_score = ['IForest Score', 'SR Score', 'RC-Forest Score', 'Luminol Score', 'LOF Score']
col_label = ['IForest Label', 'SR Label', 'RC-Forest Label', 'Luminol Label', 'LOF Label']

train_data_uad = data_uad.iloc[:, 5:].copy()

train_score_uad = data_uad[col_score].copy()
train_label_uad = data_uad[col_label].copy()

"""## **3.2 Test set**"""

df = test_data.copy()

pca = PCA(n_components=1)
# Chuẩn hóa dữ liệu
normalized_df = (df - df.mean()) / df.std()
# Thực hiện PCA
transformed_df = pca.fit_transform(normalized_df)

data_uad_test = uad(transformed_df, df)

col_score = ['IForest Score', 'SR Score', 'RC-Forest Score', 'Luminol Score', 'LOF Score']
col_label = ['IForest Label', 'SR Label', 'RC-Forest Label', 'Luminol Label', 'LOF Label']
test_data_uad = data_uad_test.iloc[:, 5:].copy()

test_score_uad = data_uad_test[col_score].copy()
test_label_uad = data_uad_test[col_label].copy()

"""# **4. Save data**"""

path_uad = '/content/drive/MyDrive/Học kì 6/DS200/Dataset/UAD/'

train_data_uad.to_csv(path_uad+'train_data_uad.csv')
train_score_uad.to_csv(path_uad+'train_score_uad.csv')
train_label_uad.to_csv(path_uad+'train_label_uad.csv')

test_data_uad.to_csv(path_uad+'test_data_uad.csv')
test_score_uad.to_csv(path_uad+'test_score_uad.csv')
test_label_uad.to_csv(path_uad+'test_label_uad.csv')

train_data_uad

train_score_uad

train_label_uad

test_data_uad

test_score_uad

test_label_uad